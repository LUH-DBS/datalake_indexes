{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import logging\n",
    "from data_handler import DataHandler\n",
    "from cocoa import COCOA\n",
    "from mate import MATE\n",
    "import psycopg2\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import json\n",
    "import qgrid\n",
    "\n",
    "\n",
    "def highlight_columns(table, query_columns, target=None, rows=10):\n",
    "    def highlight_query(s):\n",
    "        color = 'lightgreen'\n",
    "        return 'background-color: %s' % color\n",
    "    \n",
    "    def highlight_target(s):\n",
    "        color = 'orange'\n",
    "        return 'background-color: %s' % color\n",
    "    \n",
    "    sample = table.head(rows).style.applymap(highlight_query, subset=pd.IndexSlice[:, query_columns])\n",
    "    if target:\n",
    "        sample = sample.applymap(highlight_target, subset=pd.IndexSlice[:, target])\n",
    "\n",
    "    return sample\n",
    "\n",
    "\n",
    "#logging.basicConfig(format='%(asctime)s %(message)s')\n",
    "#logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "db_config = json.load(open(\"/Users/jannisbecktepe/Developer/db_config.json\"))\n",
    "\n",
    "conn = psycopg2.connect(**db_config)\n",
    "data_handler = DataHandler(\n",
    "    conn,\n",
    "    main_table='cafe_gittables2_main_tokenized',\n",
    "    column_headers_table='cafe_gittables2_column_headers',\n",
    "    table_info_table='cafe_gittables2_table_info',\n",
    "    cocoa_index_table='cafe_gittables2_cocoa_index'\n",
    ")\n",
    "\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Demonstrating Multi-attribute and Order-indexes for Data Discovery\n",
    "## 1) Input Preparation\n",
    "### Select input and target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_dataset_name, input_dataset = data_handler.read_csv('../datasets/movie.csv')\n",
    "display(HTML(input_dataset.head(10).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_columns = ['director_name', 'movie_title']\n",
    "target_column = 'imdb_score'\n",
    "\n",
    "input_sample = highlight_columns(input_dataset, input_columns, target=[target_column])\n",
    "display(HTML(input_sample.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2) Joinability Discovery\n",
    "\n",
    "### Find top-10 joinable tables using Super Key Index and MATE Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mate = MATE(data_handler)\n",
    "top_joinable_tables = mate.enrich(input_dataset,\n",
    "                                  input_columns,\n",
    "                                  50,\n",
    "                                  dataset_name=input_dataset_name)\n",
    "\n",
    "joinable_columns_dict = {}\n",
    "tables_dict = {}\n",
    "column_headers_dict = {}\n",
    "for score, table_id, columns, join_map in top_joinable_tables:\n",
    "    joinable_columns_dict[table_id] = columns\n",
    "\n",
    "    try:\n",
    "        table = data_handler.get_table(table_id)\n",
    "    except:\n",
    "        continue\n",
    "    tables_dict[table_id] = table\n",
    "    \n",
    "    column_headers = [table.columns[int(col_id)] for col_id in columns.split('_')][:len(input_columns)]\n",
    "    column_headers_dict[table_id] = column_headers\n",
    "    highlight_sample = highlight_columns(table, column_headers)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect top joinable tables\n",
    "### #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "top_table_index = 1\n",
    "\n",
    "score, table_id, columns, join_map = top_joinable_tables[top_table_index]\n",
    "\n",
    "tables_dict[table_id].to_csv(\"../datasets/test.csv\", index=False)\n",
    "print(f'Score: {score}, table_id: {table_id}, joinable columns: {columns}, #rows: {tables_dict[table_id].shape[0]}, #columns: {tables_dict[table_id].shape[1]}')\n",
    "highlight_sample = highlight_columns(tables_dict[table_id], column_headers_dict[table_id])\n",
    "\n",
    "\n",
    "display(HTML(highlight_sample.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_table_index = 2\n",
    "\n",
    "score, table_id, columns, join_map = top_joinable_tables[top_table_index]\n",
    "tables_dict[table_id].to_csv(\"../datasets/test.csv\", index=False)\n",
    "print(f'Score: {score}, table_id: {table_id}, joinable columns: {columns}, #rows: {tables_dict[table_id].shape[0]}, #columns: {tables_dict[table_id].shape[1]}')\n",
    "highlight_sample = highlight_columns(tables_dict[table_id], column_headers_dict[table_id])\n",
    "\n",
    "\n",
    "display(HTML(highlight_sample.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Duplicate Detection using Xash\n",
    "## Discover duplicate tables and their relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duplicate_detection import DuplicateDetection\n",
    "import time\n",
    "\n",
    "dup = DuplicateDetection(data_handler)\n",
    "\n",
    "\n",
    "duplicate_detection_start = time.time()\n",
    "duplicate_tables = []\n",
    "for _, table_id, _, _ in top_joinable_tables:\n",
    "    table = tables_dict[table_id]\n",
    "    duplicate_tables += dup.get_duplicate_tables(table)\n",
    "\n",
    "duplicate_relations = dup.get_relations(duplicate_tables)\n",
    "print(f\"\\nTotal runtime: {time.time() - duplicate_detection_start:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Duplicates Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "import pandas as pd\n",
    "\n",
    "net = Network(height='1000px', width='100%',notebook=True)\n",
    "\n",
    "for t in duplicate_relations:\n",
    "    net.add_node(t[0],str(t[0]))\n",
    "    net.add_node(t[1],str(t[1]))\n",
    "    net.add_edge(t[0], t[1])\n",
    "    \n",
    "#net.add_node(0,\"0\")\n",
    "#for t in duplicate_tables_first:\n",
    "#    net.add_node(t,str(t))\n",
    "#    net.add_edge(0, t)\n",
    "\n",
    "net.show_buttons(filter_=['physics'])\n",
    "net.set_edge_smooth(\"dynamic\")\n",
    "net.toggle_stabilization(False)\n",
    "net.toggle_physics(False)\n",
    "\n",
    "# Get row values to generate html tables:\n",
    "output = \"\"\n",
    "for table_id in duplicate_tables:\n",
    "    #print(data_handler.get_table(table_id).head(10).to_html())\n",
    "    output += data_handler.get_table(table_id).to_html(table_id=f\"t{table_id}\", index=None)\n",
    "    \n",
    "# Convert CSV table to html table\n",
    "output = output + table.iloc[:10,:].to_html(table_id='t0', index=None)\n",
    "\n",
    "with open(\"template.html\", 'r') as file :\n",
    "  filedata = file.read()\n",
    "\n",
    "# Replace table placeholder with actual tables html\n",
    "filedata = filedata.replace('%%tables_placeholder%%', output)\n",
    "\n",
    "with open(\"template_new.html\", 'w') as file:\n",
    "  file.write(filedata)\n",
    "\n",
    "net.prep_notebook(custom_template=True, custom_template_path=\"template_new.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw duplicates graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.show(\"nb.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicates from joinable tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# group relations by first table in tuple\n",
    "duplicates_dict = defaultdict(list)\n",
    "for t1, t2 in duplicate_relations:\n",
    "    duplicates_dict[t1] += [t2]\n",
    "    \n",
    "# merge dictionary into groups\n",
    "remove_tables = []    # tables that will be removed\n",
    "for t1 in duplicates_dict:\n",
    "    for t2 in duplicates_dict[t1]:\n",
    "        if t2 in duplicates_dict:\n",
    "            duplicates_dict[t1] += duplicates_dict[t2]\n",
    "            duplicates_dict[t2] = []\n",
    "    duplicates_dict[t1] = list(set(duplicates_dict[t1]))\n",
    "    remove_tables += duplicates_dict[t1]\n",
    "\n",
    "top_joinable_tables_filtered = []\n",
    "for i in range(len(top_joinable_tables)):\n",
    "    if top_joinable_tables[i][1] not in remove_tables:\n",
    "        top_joinable_tables_filtered += [top_joinable_tables[i]]\n",
    "\n",
    "print(\"Original joinable tables:\")\n",
    "print([table[1] for table in top_joinable_tables])\n",
    "\n",
    "print(\"\\nJoinable tables without duplicates:\")\n",
    "print([table[1] for table in top_joinable_tables_filtered])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 4) Correlation Calculation\n",
    "## Obtain top-5 correlating features using Order Index and COCOA Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from util import get_cleaned_text\n",
    "cocoa = COCOA(data_handler)\n",
    "top_correlating_columns = cocoa.enrich_multicolumn(input_dataset, top_joinable_tables_filtered, 5, target_column=target_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize top correlating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add tokenized input columns for the join\n",
    "output_dataset = input_dataset.copy()\n",
    "for input_column in input_columns:\n",
    "    output_dataset[input_column + \"_tokenized\"] = input_dataset[input_column].apply(get_cleaned_text)\n",
    "\n",
    "external_columns = []\n",
    "for cor, table_col_id in top_correlating_columns[:3]:\n",
    "    table_id = int(table_col_id.split('_')[0])\n",
    "    column_id = int(table_col_id.split('_')[1])\n",
    "    table = tables_dict[table_id]\n",
    "    \n",
    "    # add correlation info\n",
    "    new_col_name = f\"{table_id}_{table.columns[column_id]}, cor: {cor:.2f}\"\n",
    "    external_columns += [new_col_name]\n",
    "    table = table.rename(columns={table.columns[column_id]: new_col_name})\n",
    "    \n",
    "    table = table.loc[:, column_headers_dict[table_id] + [table.columns[column_id]]]\n",
    "\n",
    "    output_dataset = output_dataset.merge(\n",
    "        table,\n",
    "        how=\"left\",\n",
    "        left_on=[col + \"_tokenized\" for col in input_columns],\n",
    "        right_on=column_headers_dict[table_id],\n",
    "        suffixes=('', '_extern')\n",
    "    )\n",
    "    # remove external join columns\n",
    "    for ext_col in column_headers_dict[table_id]:\n",
    "        if ext_col not in input_columns:\n",
    "            output_dataset = output_dataset.drop(columns=[ext_col])\n",
    "    \n",
    "    output_dataset = output_dataset[[c for c in output_dataset.columns if not c.endswith('_extern')]]\n",
    "\n",
    "output_dataset = output_dataset[[c for c in output_dataset.columns if not c.endswith('_tokenized')]]\n",
    "\n",
    "output_sample = highlight_columns(output_dataset, input_columns, target=external_columns)\n",
    "display(HTML(output_sample.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Materialize join for selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataset = output_dataset.iloc[:, [0, 1, 2, 3, 4, 5, 6]]\n",
    "display(HTML(output_dataset.head(10).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
